# train.py
# GCN Model Definition (Paste this in the same cell)
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv

def add_balanced_masks(data):
    labels = data.y
    anomaly_indices = torch.nonzero(labels == 1).view(-1)
    normal_indices = torch.nonzero(labels == 0).view(-1)

    train_anomalies = anomaly_indices[:int(0.6 * len(anomaly_indices))]
    train_normals = normal_indices[:int(0.6 * len(normal_indices))]
    val_anomalies = anomaly_indices[int(0.6 * len(anomaly_indices)):int(0.8 * len(anomaly_indices))]
    val_normals = normal_indices[int(0.6 * len(normal_indices)):int(0.8 * len(normal_indices))]
    test_anomalies = anomaly_indices[int(0.8 * len(anomaly_indices)):]
    test_normals = normal_indices[int(0.8 * len(normal_indices)):]

    train_idx = torch.cat([train_anomalies, train_normals])
    val_idx = torch.cat([val_anomalies, val_normals])
    test_idx = torch.cat([test_anomalies, test_normals])

    data.train_mask = torch.zeros_like(labels, dtype=torch.bool)
    data.val_mask = torch.zeros_like(labels, dtype=torch.bool)
    data.test_mask = torch.zeros_like(labels, dtype=torch.bool)

    data.train_mask[train_idx] = True
    data.val_mask[val_idx] = True
    data.test_mask[test_idx] = True

    return data


class GCNNet(nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels):
        super().__init__()
        self.conv1 = GCNConv(in_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, out_channels)

    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        x = F.relu(self.conv1(x, edge_index))
        x = F.dropout(x, training=self.training)
        x = self.conv2(x, edge_index)
        return x


data = load_and_simulate_graph("smart_grid_dataset.csv", num_nodes=50)
num_nodes = data.num_nodes
data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)
test_indices = torch.randperm(num_nodes)[:int(0.3 * num_nodes)]
data.test_mask[test_indices] = True

data = add_balanced_masks(data)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = GCNNet(in_channels=data.num_node_features, hidden_channels=16, out_channels=2).to(device)
data = data.to(device)

class_counts = torch.bincount(data.y[data.train_mask])
class_weights = 1.0 / class_counts.float()
criterion = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 2.5]).to(device))

optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

best_val_loss = float('inf')
patience, patience_counter = 20, 0
best_model_state = None

for epoch in range(1, 101):
    patience=50
    model.train()
    optimizer.zero_grad()
    out = model(data)
    loss = criterion(out[data.train_mask], data.y[data.train_mask])
    loss.backward()
    optimizer.step()

    # Validation loss
    model.eval()
    with torch.no_grad():
        val_out = model(data)
        val_loss = criterion(val_out[data.val_mask], data.y[data.val_mask])
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_model_state = model.state_dict()
            patience_counter = 0
        else:
            patience_counter += 1

    if epoch % 20 == 0:
        print(f"Epoch {epoch} | Train Loss: {loss.item():.4f} | Val Loss: {val_loss.item():.4f}")

    if patience_counter >= patience:
        print("⏹️ Early stopping triggered.")
        break
